import os
import openai
import requests
from bs4 import BeautifulSoup
from pptx import Presentation
from tqdm import tqdm
from dotenv import load_dotenv
from openai import OpenAI

# Load API keys
load_dotenv()
SERPER_API_KEY = os.getenv("SERPER_API_KEY")
openai.api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# Search the web using Serper.dev
def search_serper(query):
    headers = {"X-API-KEY": SERPER_API_KEY}
    data = {"q": query}
    res = requests.post("https://google.serper.dev/search", headers=headers, json=data)
    results = res.json().get("organic", [])
    return [result["link"] for result in results[:5]]

# Scrape text from a web page
def fetch_page_text(url):
    try:
        res = requests.get(url, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        for script in soup(["script", "style"]): script.decompose()
        return ' '.join(soup.stripped_strings)
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return ""

# Summarize content using OpenAI
def summarize_content(text):
    prompt = f"""
You are an educational assistant. Take the following content and generate a structured PowerPoint outline. 
Return a JSON object where each key is a slide title and each value is the corresponding explanation.
Keep it 5-7 slides maximum. Write clear and concise text for high school-level students.

CONTENT:
{text[:3000]}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    # Parse structured JSON from LLM output
    import json
    try:
        structured = json.loads(response.choices[0].message.content.strip())
    except Exception as e:
        print("‚ö†Ô∏è Failed to parse JSON from model response.")
        print("Raw output:\n", response.choices[0].message.content)
        raise e

    return structured


# Generate a PowerPoint presentation
def generate_ppt(slide_data: dict, topic: str):
    prs = Presentation()
    title_slide_layout = prs.slide_layouts[0]
    content_slide_layout = prs.slide_layouts[1]

    # Title Slide
    title_slide = prs.slides.add_slide(title_slide_layout)
    title_slide.shapes.title.text = topic
    title_slide.placeholders[1].text = "Generated by AI Task Automator"

    # Content Slides
    for title, content in slide_data.items():
        slide = prs.slides.add_slide(content_slide_layout)
        slide.shapes.title.text = title
        slide.placeholders[1].text = content

    filename = f"output/{topic.replace(' ', '_')}.pptx"
    os.makedirs("output", exist_ok=True)
    prs.save(filename)
    return filename


# Main pipeline
def main():
    topic = input("üìö Enter your homework topic: ").strip()
    print("\nüîç Searching the web...")
    urls = search_serper(topic)

    full_text = ""
    for url in tqdm(urls, desc="üì• Fetching content"):
        full_text += fetch_page_text(url) + "\n"

    print("‚úçÔ∏è Summarizing content...")
    summary = summarize_content(full_text)

    print("üìä Generating slides...")
    ppt_path = generate_ppt(summary, topic)

    # Save text summary
    txt_path = f"output/{topic.replace(' ', '_')}_summary.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        for title, content in summary.items():
            f.write(f"{title}\n{'-'*len(title)}\n{content}\n\n")

    print(f"\n‚úÖ Done! Files saved:\n- {ppt_path}\n- {txt_path}")

if __name__ == "__main__":
    main()
